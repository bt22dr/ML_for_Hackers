---
title: "최적화"
output: html_document
---
```{r echo=FALSE}
library(ggplot2)
```

### 최적화에 대한 소개 ###
지금까지 소개한 내용은 알고리즘 내부를 블랙박스처럼 처리하여 입력과 출력에만 초점을 맞춰 설명했고,  
단순히 기계학습 알고리즘을 라이브러리 함수처럼 활용해서 예측 작업을 했다.

이 장에서 다룰 내용 개관

* 예측 변수 하나에 단순 선형 회귀 모형을 적합(fitting)시키는 함수 작성
* 최적화 문제에서 모형을 데이터에 적합시키는 과정 살펴보기
* 사례분석. 암호화된 문서를 해독하는 간단한 해독기 만들기

최적화 문제 :  
기계의 손잡이를 돌려서 설정을 바꾸어 가며 기계가 얼마나 잘 작동하는지 측정하는 방법이 있다고 하자.  
기계의 성능을 측정하는 어떤 값이 최대가 되는 점을 최적(optimum)점이라고 하고,  
그 점에 도달하는 것을 최적화(optimization)이라고 한다. ex) 여자 꼬시기

키와 몸무게 데이터로 선형 회귀 함수를 직접 작성해보자.  
몸무게가 키의 함수로 예측될 수 있다고 가정하면 다음과 같은 선형 함수를 만들 수 있다. 
```{r}
height.to.weight <- function(height, a, b)
{
  return(a + b * height)
}
```

위 함수에서 어떤 a와 b 값이 최적인지 어떻게 결정할 수 있을까? 여기서 최적화가 등장한다.  

1. 먼저 키 데이터로 몸무게가 얼마나 잘 예측되는지 측정하는 값을 정의하고
2. a와 b 값을 바꾸어가며 예측 성능이 최대가 되는 지점을 찾는다. 

사실 lm에 필요한 기능이 다 있다. lm에는...

* 최적화를 시킬 간단한 오차 함수(error function)가 있어서,
* 일반 선형 회귀에만 동작하는 특수한 알고리즘으로 a와 b의 최적값을 찾는다. 

```{r}
heights.weights <- read.csv(file.path('data', '01_heights_weights_genders.csv'))
coef(lm(Weight ~ Height, data = heights.weights))
```

**오차함수**  
lm은 제곱 오차(squared error)에 기반한 오차 측도를 사용하는데 간단히 설명하면 아래와 같다. 

1. a와 b의 값을 고정한다. 
2. 주어진 키 값에 대해서 몸무게를 추정한다. 
3. 실제 몸무게에서 예측 몸무게를 뺀다. 이 값을 오차로 한다. 
4. 오차를 제곱한다. 
5. 모든 값에 대해 제곱한 오차를 더해서 제곱 오차 총합을 구한다. 

이 방법대로 구현된 코드를 보자. 
```{r}
squared.error <- function(heights.weights, a, b)
{
  predictions <- with(heights.weights, height.to.weight(Height, a, b))
  errors <- with(heights.weights, Weight - predictions)
  return(sum(errors ^ 2))
}
```

몇 가지 a와 b의 값에 대한 squared.error를 계산해보면  
특정 a와 b값에 대해서는 제곱 오차가 훨씬 더 낮음을 알 수 있다.  
이 말은 곧 예측 능력을 말해주는 의미 있는 오차 함수가 있으므로 최적의 a와 b 값을 찾을 차례라는 뜻.  
최대화나 최소화를 할 측도를 설정하는 일이 바로 최적화 문제의 시작이 된다.  
이 측도는 보통 목적 함수(objective function)이라고 불린다.  
=> 최적화 문제 : 목적 함수를 가능한 가장 작거나 크게 만드는 최적의 a, b 값을 구하는 문제 

최적값을 구하는 방법

* 격자 검색(grid search)
* optim 함수 사용

**격자 검색**  
a, b 값의 범위를 충분히 크게 설정하여 모든 경우에 대한 squared.error를 구한 후에  
가장 작은 squared.error 값을 산출하는 a, b 쌍을 골라내는 방식
```{r}
for (a in seq(-1, 1, by = 1))
{
  for (b in seq(-1, 1, by = 1))
  {
    print(squared.error(heights.weights, a, b))
  }
}
```

문제점 : 검색한 격자상에서는 항상 최적 값을 얻게 되므로 비합리적이지는 않지만 심각한 문제 몇 가지가 있다. 

* 격자의 간격 : 올바른 해상도는 무엇인지? 질문에 답하는 것은 격자의 간격을 구하는 또 다른 최적화 문제가 된다. 
* 차원의 저주(Curse of Dimensionality) : 변수가 100개고 변수당 10개의 점을 계산하는 경우의 수는 10^100개나 된다. 

수백 또는 수천 개의 입력값에 대해 선형 회귀를 한다면 격자 검색은 적당치 않다. 그렇다면 뭘 할 수 있을까?  
=> optim 함수로 최적화 수행. 

** optim 사용 **
optim 함수의 인자는 아래와 같다.

* 최적화의 시작점 수치벡터 : a와 b의 기본값으로 c(0, 0) 벡터를 전달
* x라는 벡터를 인수로 받는 함수 : 오차 함수를 x만 익명으로 받는 익명 함수로 감싸서 전달

```{r}
optim(c(0, 0),
      function (x)
      {
        squared.error(heights.weights, x[1], x[2])
      })
```

optim 함수의 수행 결과 

* par (parameter) : lm으로 구한 값과 매우 비슷한 것을 확인할 수 있다.  
lm은 optim 코드보다 더 자세한 선형 회귀 알고리즘을 쓰므로 결과도 더 정밀하다.  
직접 자신의 문제를 푼다면 선형 회귀 방법 대신 다른 모형을 쓸 수도 있으므로 optim을 쓰는 편이 낫다.
* value : optim에서 최적으로 나온 모수에서의 제곱 오차 값
* convergence : optim이 찾은 변수가 최적 값인지 아닌지 알려주는 값 (제대로 계산됐다면 이 값은 0이 된다)

optim의 상세는 최적화에 도움이 되는 수많은 미적분학 개념에 기반한 복잡한 내용이므로 스킵  
하지만 optim이 일반적으로 하는 일을 시각적으로 이해하기는 매우 쉽다. 

b값이 0으로 고정되었을 때 최적의 a값을 찾는다고 가정해보자. 
```{r}
a.error <- function(a)
{
  return(squared.error(heights.weights, a, 0))
}
```

최적의 a값이 있는지 이해하려면 curve 함수를 이용해서 여러 x값에 대해 a.error를 그래프로 그려본다. 
```{r}
curve(sapply(x, function (a) {a.error(a)}), from = -1000, to = 1000)
```

전역 최적점(global optimum)이 존재한다.

이 경우 optim은 제곱 오차 함수의 모양을 활용해서  
 - 특정 a값에서의 오차를 계산하고  
 - 다음으로 진행할 방향을 알아내게 된다.  
 이렇게 optim은 전체적인 구조에 대한 지역적 정보를 알아내서 매우 빠르게 최적점을 찾아낸다. 

a를 고정하고 b를 바꿀 때 오차 함수가 어떻게 반응하는지도 살펴보자.
```{r}
b.error <- function(b)
{
  return(squared.error(heights.weights, 0, b))
}

curve(sapply(x, function (b) {b.error(b)}), from = -1000, to = 1000)
```

a와 b 모두 전역 최적점이 있다는 사실은 optim으로 오차 함수를 최소화하는  
하나의 최적 a, b 값을 찾는게 가능하다는 뜻이 된다.

일반적인 경우에서도 이 방식은 지금 계산중인 어떤 점에 대한 정보만으로 주위 점을 추측하므로  
즉, 점 주위 정보로 성능이 더 나아지는 방향으로 다음에 움직일 방향이 결정되는 적응식 방법을 사용하므로  
격자검색보다 더 빠르고 효율적으로 최적점을 계산할 수 있다. 

### 능선회귀(Ridge Regression) ###
optim의 사용법을 알았으니 능선 회귀를 구현해보자.  

일반 최소제곱 회귀와 능선 회귀의 차이점은  

* 오차함수 : 회귀 계수의 크기도 오차 항의 일부로 간주한다
* lambda : 과적합을 피하기 위해 a와 b값의 최소화와 제곱 오차 최소화 사이에 균형을 잡아주는 변수

일단 lambda값이 정해지면, 능선 오차 함수를 다음과 같이 작성할 수 있다.  
(제대로 된 lambda값은 교차검증법(cross-validation)으로 구할 수 있으며 여기서는 간단히 1이라 가정한다)
```{r}
ridge.error <- function(heights.weights, a, b, lambda)
{
  predictions <- with(heights.weights, height.to.weight(Height, a, b))
  errors <- with(heights.weights, Weight - predictions)
  return(sum(errors ^ 2) + lambda * (a ^ 2 + b ^ 2))
}
```

일반 최소 제곱 문제와 마찬가지로 optim을 이용하면 쉽게 능선 회귀 문제를 풀 수 있다.  
결과를 보면 lm으로 구했던 값보다 살짝 작은 값이 나온 것을 확인할 수 있다. 
```{r}
lambda <- 1

optim(c(0, 0),
      function (x)
      {
        ridge.error(heights.weights, x[1], x[2], lambda)
      })
```

사실 좋은 예제는 아님 제대로 보려면 $x^2, x^3, ..., x^{14}$ 같은 다항식(polynomial)을 포함하는 예제가 좋다.  
(TODO: 아래와 같은 데이터를 가정해보자...)
```{r echo=FALSE, eval=FALSE}
set.seed(1)

x <- seq(0, 1, by = 0.01)
y <- sin(2 * pi * x) + rnorm(length(x), 0, 0.1)

df <- data.frame(X = x, Y = y)
ggplot(df, aes(x = X, y = Y)) +
  geom_point()

poly.fit <- lm(Y ~ poly(X, degree = 25), data = df)
df <- transform(df, PredictedY = predict(poly.fit))
ggplot(df, aes(x = X, y = PredictedY)) +
  geom_point() +
  geom_line()





my_data <- poly(df$X, degree = 25)

predict_y <- function(x, param)
{
  return(param[1] + sum(param[2:length(param)] * x))
}

ridge.error <- function(data, param, lambda) {
  predictions <- predict_y(data, param)
  errors <- y - predictions
  return(sum(errors ^ 2) + lambda * sum(param^2))
}

lambda <- 0.025

par <- optim(rep(0, 26),
      function (parma)
      {
        ridge.error(my_data, parma, lambda)
      })$par


my_y <- apply(my_data, 1, function(x) { predict_y(x, par) })
df <- data.frame(x, my_y)

ggplot(df, aes(x = x, y = my_y)) +
  geom_point() +
  geom_line()
```

오차 함수를 그려보면 일반 선형 회귀와 마찬가지로 능선 회귀에서도 optim이 잘 동작하는지 알 수 있다. 
```{r}
a.ridge.error <- function(a, lambda)
{
  return(ridge.error(heights.weights, a, 0, lambda))
}
curve(sapply(x, function (a) {a.ridge.error(a, lambda)}), from = -1000, to = 1000)

b.ridge.error <- function(b, lambda)
{
  return(ridge.error(heights.weights, 0, b, lambda))
}
curve(sapply(x, function (b) {b.ridge.error(b, lambda)}), from = -1000, to = 1000)
```

optim 같은 함수를 써서 예측 오차 측도를 최적화하는 방법만 알아도 기계학습에 관한 여러 가지 작업이 가능하다.  
다양한 오차 함수를 고안해서 자신만의 예제에 적용해보기를 권한다. 

예를 들어, 아래와 같은 절대값 오차 함수를 시험해보면 어떨까?  
미적분학 기법에 관한 이유 때문에 optim에서 이 오차항은 잘 동작하지 않는다. 
```{r}
absolute.error <- function(heights.weights, a, b)
{
  predictions <- with(heights.weights, height.to.weight(Height, a, b))
  errors <- with(heights.weights, Weight - predictions)
  return(sum(abs(errors)))
}

a.absolute.error <- function(a)
{
  return(absolute.error(heights.weights, a, 0))
}

curve(sapply(x, function (a) {a.absolute.error(a)}), from = -1000, to = 1000)
```

잘 동작하지 않는 이유를 시각적으로 개념만 설명하면... 
절대값 오차 곡선이 제곱 오차나 능선 오차 곡선보다 훨씬 더 뾰족하다.  
너무 뾰족한 모양이라 optim이 특정 점에서 진행 방향을 못 찾게 되고 최적점에도 도달하지 못한다.  
즉, 꼭지점에서 미분이 불가능하기 때문에 기울기를 구할 수가 없고,  
따라서 위치를 조금씩 바꾸면서 최적점을 탐색하는 방법을 쓸 수 없다는 말이다. 

### 최적화로 암호 해독하기 ###
회귀 모형 외에도 거의 대부분의 기계학습 알고리즘은 어떤 예측 오차 측도를 최소화하는 최적화 문제로 볼 수 있다.  
확률적 최적화(stochastic optimization) : 가능한 범위 내에서 파라미터를 약간씩 무작위로 바꾸되,  
오차 함수가 상승보다는 하락하는 경향이 되도록 방향을 잡아나가는 방법이다. 

이러한 방법론은 모의 담금질(simulated annealing), 유전 알고리즘(genetic algorithm),  
마르코프 연쇄 몬테 카를로 방법(Markov chain Monte Carlo, MCMC) 같은 유명한 최적화 알고리즘들과 연관이 있다. 

여기서 암호 해독을 위해 사용할 알고리즘은 메트로폴리스 방법(Metropolis method)이다.  
암호 해독은 optim 같은 발군의 알고리즘도 전혀 동작하지 못하는 예제이다. 

문제 : 문자치환식 암호법으로 암호화된 문자열이 있을 때 원본을 해독하는 규칙은 어떻게 정해야 할까?
(문자치환식 암호법, ROT13, 카이사르 암호법)  

우선 카이사르 암호를 만들어보자.
```{r}
english.letters <- c('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k',
                     'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v',
                     'w', 'x', 'y', 'z')

caesar.cipher <- list()

inverse.caesar.cipher <- list()

for (index in 1:length(english.letters))
{
  caesar.cipher[[english.letters[index]]] <- english.letters[index %% 26 + 1]
  inverse.caesar.cipher[[english.letters[index %% 26 + 1]]] <- english.letters[index]
}

print(head(caesar.cipher))
```

암호를 구현했으므로 문자열을 암호로 바꾸는 함수를 만들자. 
```{r}
apply.cipher.to.string <- function(string, cipher)
{
  output <- ''

  for (i in 1:nchar(string))
  {
  output <- paste(output, cipher[[substr(string, i, i)]], sep = '')
  }
  
  return(output)
}

apply.cipher.to.text <- function(text, cipher)
{
  output <- c()
  
  for (string in text)
  {
    output <- c(output, apply.cipher.to.string(string, cipher))
  }
  
  return(output)
}

apply.cipher.to.text(c('sample', 'text'), caesar.cipher)
```

기본 도구를 만들었으니 암호 해독 문제를 몇 가지 부분으로 나눠서 풀어보자.

1. 주어진 해독 규칙의 성능을 평가하는 측도를 정의한다. 
2. 현재 가장 좋은 성능의 규칙을 무작위로 바꾸어 새로운 해독 규칙을 생성하는 알고리즘 만든다.
3. 그 해독 규칙 중에 더 나은 성능을 보이는 쪽으로 이동하는 알고리즘을 정의한다. 

##### 1. 해독 규칙의 성능을 측정하는 법 구현 #####
문자치환법으로 암호화된 문서 조각 "wfoj wjej wjdj"이 있다고 가정해보자. (veni vidi vici)  
여기서 사용할 접근법은 암호화된 메시지가 일반 영어로 바뀐다면 그 규칙이 좋다고 말하는것.  
예를 들어, A와 B라는 해독 규칙을 적용한 메시지가 아래와 같다면 A가 더 낫다는게 뚜렷하다. 

* decrypt(T, A) = xgpk xkfk xkek
* decrypt(T, B) = veni vidi vici

이와 같은 인간의 직관을 컴퓨터가 실행하는 자동 프로그램으로 바꾸기 위해서  
어휘별로 출현 확률을 기록한 데이터베이스를 이용하려 한다. (존재하지 않는 단어는 epsilon으로)  
해독된 문서에 있는 모든 단어의 확률을 어휘 데이터베이스에서 찾아 곱한 값을  
전체 문서의 확률 추정값으로 하고, 그 값으로 우선순위를 매길 수 있다.

어휘 데이터베이스로 해독된 문서의 확률을 계산하는 식으로 특정 해독 규칙에 대한 오차 측도를 만들 수 있고,  
오차 함수가 생겼으니 암호 해독 문제는 전적으로 최적화 문제로 바뀌게 된다. 

하지만 확률이 가장 높은 해독 규칙을 찾는 문제는 optim으로 최적화하는 종류의 문제와는 거리가 멀다.  
해독 규칙은 그래프로 그리지 못하기 때문에 매끄러운 곡선을 이용해 더 나은 규칙을 찾는 방식은 적용 불가능.  
이 문제를 풀려면 완전히 새로운 최적화 방법이 필요 ==> 메트로폴리스 알고리즘

메트로폴리스 알고리즘  

* 기본 개념 : 임의의 해독 규칙에서 시작해서 반복적으로 개선하면서 최종적으로 그럴듯한 해답을 얻는 방식  
* 구현 : 완전히 임의의 규칙에서부터 개선해나가는 연산을 아주 많은 횟수로(ex. 50,000번) 반복한다. 
* 특징 : 얼마나 반복해야 원하는 결과가 나올지는 보장할 수 없지만,  
각 단계마다 더 나은 규칙을 찾아가는 경향이 있으므로 연산을 반복하면 마지막에는 적당한 결과를 얻게 된다. 
* 단점 : 상당한 계산 시간이 지난 후에도 해답이 나왔는지 확신 못함.  
게다가 기다리는 시간 동안에 알고리즘이 정답을 찾아가고 있다고 말하기도 어렵다. 

##### 새로운 생성 규칙 생성 알고리즘 #####
현재 규칙에서 한 문자를 무작위로 골라서 문자치환 규칙에 따라 자동으로 선택되는 다른 문자와 바꿔주는 과정  
단순한 접근 : 해독 문서의 확률이 증가할 때만 새로운 규칙을 채택하도록 한다.  
이러한 탐욕적 최적화(greedy optimization) 방법을 쓰면 좋지 않은 규칙에만 묶이게 되는 경향이 있으므로  
다음과 같이 원 규칙 A와 새로운 규칙 B중에 하나를 선택하는 비탐욕정 방법을 사용한다.  

* 규칙 B로 해독된 문서의 확률이 규칙 A로 해독된 문서의 확률보다 크면 A를 B로 바꾼다.  
* 규칙 B로 해독된 문서의 확률이 규칙 A로 해독된 문서의 확률보다 작아도 가끔씩 A를 B로 바꾸어 준다. 

규칙 변경 함수의 코드는 아래와 같다. 
```{r}
generate.random.cipher <- function()
{
  cipher <- list()
  
  inputs <- english.letters
  
  outputs <- english.letters[sample(1:length(english.letters), length(english.letters))]
  
  for (index in 1:length(english.letters))
  {
    cipher[[inputs[index]]] <- outputs[index]
  }
  
  return(cipher)
}

modify.cipher <- function(cipher, input, output)
{
  new.cipher <- cipher
  
  new.cipher[[input]] <- output
  
  old.output <- cipher[[input]]
  
  collateral.input <- names(which(sapply(names(cipher),
                                         function (key) {cipher[[key]]}) == output))
  
  new.cipher[[collateral.input]] <- old.output
  
  return(new.cipher)
}

propose.modified.cipher <- function(cipher)
{
  input <- sample(names(cipher), 1)
  
  output <- sample(english.letters, 1)
  
  return(modify.cipher(cipher, input, output))
}
```

앞에서 소개한 두 가지 코드(규칙 변경 함수, 새로운 규칙 채택 과정)를 조합하면  
현재 규칙보다 확실히 좋지 않은 규칙들을 탐색하느라 시간을 낭비하는 것을 막아주면서도  
최적화 접근법의 탐욕적 특성을 완화시켜 준다. 

실질적인 작업을 시작해보자.  
1. 위키백과 문서에서 얼마나 자주 나타나는지 기록한 어휘 데이터베이스 로드하고  
간단한 단어들의 출현 빈도를 확인해보자.
```{r}
load(file.path('data', 'lexical_database.Rdata'))

lexical.database[['a']]
lexical.database[['the']]
lexical.database[['he']]
lexical.database[['she']]
lexical.database[['data']]
```

2. 문서의 확률을 계산할 방법에 대한 코드 작성. 개별 단어들에 대한 확률을 구하는 함수이다. 
```{r}
one.gram.probability <- function(one.gram, lexical.database = list())
{
  lexical.probability <- lexical.database[[one.gram]]
  
  if (is.null(lexical.probability) || is.na(lexical.probability))
  {
  return(.Machine$double.eps) # 존재하지 않는 단어에 대해서는 epsilon을 반환
  }
  else
  {
  return(lexical.probability)
  }
}
```

3. 전체 문서의 확률을 계산하는 함수 작성.  
부동소수점 연산 정밀도에 한계가 있어서 확률의 다중 곱을 계산하면 수치가 불안정해진다.  
여기서는 각 단어의 로그 확률을 더해서 문서의 로그 확률을 계산하는 방법을 쓴다. 
```{r}
log.probability.of.text <- function(text, cipher, lexical.database = list())
{
  log.probability <- 0.0
  
  for (string in text)
  {
    decrypted.string <- apply.cipher.to.string(string, cipher)
    log.probability <- log.probability +
    log(one.gram.probability(decrypted.string, lexical.database))
  }
  
  return(log.probability)
}
```

4. 메트로폴리스 알고리즘의 한 단계를 계산하는 함수 작성. 
```{r}
metropolis.step <- function(text, cipher, lexical.database = list())
{
  proposed.cipher <- propose.modified.cipher(cipher)
  
  lp1 <- log.probability.of.text(text, cipher, lexical.database)
  lp2 <- log.probability.of.text(text, proposed.cipher, lexical.database)
  
  if (lp2 > lp1)
  {
    return(proposed.cipher)
  }
  else
  {
    a <- exp(lp2 - lp1)
    x <- runif(1)
    
    if (x < a)
    {
      return(proposed.cipher)
    }
    else
    {
      return(cipher)
    }
  }
}
```

5. 문장 하나를 정해서 메트로 폴리스 알고리즘을 50,000번 수행하는 과정이 어떻게 작동하는지 살펴보자.  
각 단계마다 해독된 문장의 로그확률, 해독 내용, 제대로 해석했는지 나타내는 가변수를 기록한다. 
```{r}
# 주어진 문장을 하나의 문자형 벡터로 만든다
decrypted.text <- c('here', 'is', 'some', 'sample', 'text')

# 카이사르 암호법으로 해당 문장을 암호화
encrypted.text <- apply.cipher.to.text(decrypted.text, caesar.cipher)

# 무작위로 해독 규칙을 만든 후 
set.seed(1)
cipher <- generate.random.cipher()

# 50,000번 반복하며 result를 구함
results <- data.frame()
number.of.iterations <- 1000
for (iteration in 1:number.of.iterations)
{
  log.probability <- log.probability.of.text(encrypted.text,
                                             cipher,
                                             lexical.database)
  
  current.decrypted.text <- paste(apply.cipher.to.text(encrypted.text,
                                                       cipher),
                                  collapse = ' ')
  
  correct.text <- as.numeric(current.decrypted.text == paste(decrypted.text,
                                                             collapse = ' '))

  results <- rbind(results,
                   data.frame(Iteration = iteration,
                              LogProbability = log.probability,
                              CurrentDecryptedText = current.decrypted.text,
                              CorrectText = correct.text))
  
  cipher <- metropolis.step(encrypted.text, cipher, lexical.database)
}

head(results)
tail(results)

write.table(results,
            file = file.path('data/results.tsv'),
            row.names = FALSE,
            sep = '\t')

ggplot(results, aes(x=Iteration, y=LogProbability)) + geom_line()
```

6. 결과 분석  
45,000번째 단계부터 정답에 가까운 결과가 나오지만 최종적으로 정답에 도달하지는 못했다.  
또한 결과를 자세히 살펴보면 어느 단계에서 정답이 나왔지만 그냥 넘어가버렸음을 알 수 있다.  
이는 목적 함수가 각각의 단어들이 자주 쓰이는 단어인지만 평가하기 때문에 발생하는 문제이다.  
어떤 규칙이 출현 빈도가 높은 단어들을 골라낸다면, 문법이 틀리고 의미가 일관성이 없더라도  
그 규칙이 채택되는 경향이 있는데 bi-gram같은 정보를 더 추가한다면 문제를 피해갈 수 있다. 

메트로폴리스 알고리즘은 무작위로 최적화하는 방법이라는 점 때문에 나타나는 꽤 복잡한 문제들이 있다. 
나쁜 종자값에서 시작하면 엄청난 계산을 해야 올바른 규칙을 찾게 될지도 모른다.  
또한, 좋은 규칙에서 금방 다음으로 넘어가는 성질이 있다는 점이다.  
이는 비탐욕적 알고리즘의 특성으로 계산과정을 장시간 추적해보면 원하던 답을 지나치는 경우를 자주 볼 수 있다. 

이런 무작위 움직임을 다루는 방법 중에 잘 알려진 방법으로는 모의 담금질이라는 최적화 기법이 있다. 
이 방법은 비탐욕적인 규칙 변경의 정도를 점점 더 줄이는 방법이다. 



















